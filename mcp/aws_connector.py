#!/usr/bin/env python3
"""
Az√ºr - AWS Cloud Connector for SoulCore MCP
Translates MCP tool calls into AWS service operations
"""

import os
import json
import logging
import uuid
from datetime import datetime
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler("aws_connector.log"),
        logging.StreamHandler()
    ]
)

class AWSConnector:
    """AWS Cloud Connector for SoulCore MCP"""
    
    def __init__(self, config_path=None):
        """
        Initialize the AWS Connector
        
        Args:
            config_path (str): Path to the AWS configuration file
        """
        self.config = {}
        self.config_path = config_path or str(Path(__file__).parent / "aws_config.json")
        self.load_config()
        
    def load_config(self):
        """Load AWS configuration"""
        try:
            if os.path.exists(self.config_path):
                with open(self.config_path, "r") as f:
                    self.config = json.load(f)
                logging.info(f"Loaded AWS configuration from {self.config_path}")
            else:
                # Create default configuration
                self.config = {
                    "region": "us-west-2",
                    "profile": "default",
                    "s3": {
                        "bucket": "soulcore-data"
                    },
                    "lambda": {
                        "function_prefix": "soulcore-"
                    },
                    "dynamodb": {
                        "table_prefix": "soulcore-"
                    }
                }
                self.save_config()
                logging.info(f"Created default AWS configuration at {self.config_path}")
        except Exception as e:
            logging.error(f"Error loading AWS configuration: {str(e)}")
            self.config = {}
    
    def save_config(self):
        """Save AWS configuration"""
        try:
            with open(self.config_path, "w") as f:
                json.dump(self.config, f, indent=2)
            logging.info(f"Saved AWS configuration to {self.config_path}")
        except Exception as e:
            logging.error(f"Error saving AWS configuration: {str(e)}")
    
    def upload_to_s3(self, file_path, key=None, bucket=None):
        """
        Upload a file to AWS S3
        
        Args:
            file_path (str): Path to the file to upload
            key (str): S3 object key (defaults to filename)
            bucket (str): S3 bucket name (defaults to configured bucket)
            
        Returns:
            dict: S3 object information or error
        """
        try:
            # In a real implementation, this would use boto3
            # For now, we'll just simulate it
            if not os.path.exists(file_path):
                return {"error": f"File not found: {file_path}"}
                
            key = key or os.path.basename(file_path)
            bucket = bucket or self.config.get("s3", {}).get("bucket")
            
            if not bucket:
                return {"error": "S3 bucket not configured"}
                
            file_size = os.path.getsize(file_path)
            region = self.config.get("region", "us-west-2")
            
            logging.info(f"Uploaded file to S3: s3://{bucket}/{key} ({file_size} bytes)")
            
            return {
                "bucket": bucket,
                "key": key,
                "size": file_size,
                "url": f"https://{bucket}.s3.{region}.amazonaws.com/{key}",
                "uploaded_at": datetime.now().isoformat()
            }
        except Exception as e:
            logging.error(f"Error uploading to S3: {str(e)}")
            return {"error": str(e)}
    
    def invoke_lambda(self, function_name, payload=None):
        """
        Invoke an AWS Lambda function
        
        Args:
            function_name (str): Lambda function name
            payload (dict): Function payload
            
        Returns:
            dict: Lambda response or error
        """
        try:
            # In a real implementation, this would use boto3
            # For now, we'll just simulate it
            function_prefix = self.config.get("lambda", {}).get("function_prefix", "")
            full_function_name = f"{function_prefix}{function_name}"
            
            payload = payload or {}
            payload_str = json.dumps(payload)
            
            logging.info(f"Invoked Lambda function: {full_function_name}")
            
            # Simulate a response
            response = {
                "statusCode": 200,
                "body": {
                    "message": f"Function {full_function_name} executed successfully",
                    "input": payload,
                    "timestamp": datetime.now().isoformat()
                }
            }
            
            return response
        except Exception as e:
            logging.error(f"Error invoking Lambda function: {str(e)}")
            return {"error": str(e)}
    
    def store_in_dynamodb(self, table_name, item):
        """
        Store an item in DynamoDB
        
        Args:
            table_name (str): DynamoDB table name
            item (dict): Item to store
            
        Returns:
            dict: Operation result or error
        """
        try:
            # In a real implementation, this would use boto3
            # For now, we'll just simulate it
            table_prefix = self.config.get("dynamodb", {}).get("table_prefix", "")
            full_table_name = f"{table_prefix}{table_name}"
            
            if not isinstance(item, dict):
                return {"error": "Item must be a dictionary"}
                
            # Ensure the item has an ID
            if "id" not in item:
                item["id"] = str(uuid.uuid4())
                
            logging.info(f"Stored item in DynamoDB: {full_table_name} (ID: {item['id']})")
            
            return {
                "table": full_table_name,
                "item_id": item["id"],
                "stored_at": datetime.now().isoformat()
            }
        except Exception as e:
            logging.error(f"Error storing item in DynamoDB: {str(e)}")
            return {"error": str(e)}
    
    def query_dynamodb(self, table_name, key_name, key_value):
        """
        Query a DynamoDB table
        
        Args:
            table_name (str): DynamoDB table name
            key_name (str): Key name to query
            key_value (str): Key value to query
            
        Returns:
            dict: Query results or error
        """
        try:
            # In a real implementation, this would use boto3
            # For now, we'll just simulate it
            table_prefix = self.config.get("dynamodb", {}).get("table_prefix", "")
            full_table_name = f"{table_prefix}{table_name}"
            
            logging.info(f"Queried DynamoDB: {full_table_name} ({key_name}={key_value})")
            
            # Simulate results
            return {
                "table": full_table_name,
                "query": {
                    key_name: key_value
                },
                "items": [
                    {
                        "id": str(uuid.uuid4()),
                        key_name: key_value,
                        "created_at": datetime.now().isoformat()
                    }
                ],
                "count": 1,
                "queried_at": datetime.now().isoformat()
            }
        except Exception as e:
            logging.error(f"Error querying DynamoDB: {str(e)}")
            return {"error": str(e)}

# Register AWS tools with MCP server
def register_aws_tools(mcp_server):
    """
    Register AWS tools with the MCP server
    
    Args:
        mcp_server: MCP server instance
    """
    aws = AWSConnector()
    
    # Upload to S3 tool
    async def aws_upload_to_s3(params, metadata=None):
        file_path = params.get("file_path")
        key = params.get("key")
        bucket = params.get("bucket")
        if not file_path:
            return {"error": "file_path parameter is required"}
        return aws.upload_to_s3(file_path, key, bucket)
    
    # Invoke Lambda tool
    async def aws_invoke_lambda(params, metadata=None):
        function_name = params.get("function_name")
        payload = params.get("payload")
        if not function_name:
            return {"error": "function_name parameter is required"}
        return aws.invoke_lambda(function_name, payload)
    
    # Store in DynamoDB tool
    async def aws_store_in_dynamodb(params, metadata=None):
        table_name = params.get("table_name")
        item = params.get("item")
        if not table_name:
            return {"error": "table_name parameter is required"}
        if not item:
            return {"error": "item parameter is required"}
        return aws.store_in_dynamodb(table_name, item)
    
    # Query DynamoDB tool
    async def aws_query_dynamodb(params, metadata=None):
        table_name = params.get("table_name")
        key_name = params.get("key_name")
        key_value = params.get("key_value")
        if not table_name:
            return {"error": "table_name parameter is required"}
        if not key_name:
            return {"error": "key_name parameter is required"}
        if not key_value:
            return {"error": "key_value parameter is required"}
        return aws.query_dynamodb(table_name, key_name, key_value)
    
    # Register the tools
    mcp_server.register_tool(
        "aws_upload_to_s3",
        aws_upload_to_s3,
        "Upload a file to AWS S3",
        "focused"
    )
    
    mcp_server.register_tool(
        "aws_invoke_lambda",
        aws_invoke_lambda,
        "Invoke an AWS Lambda function",
        "technical"
    )
    
    mcp_server.register_tool(
        "aws_store_in_dynamodb",
        aws_store_in_dynamodb,
        "Store an item in DynamoDB",
        "methodical"
    )
    
    mcp_server.register_tool(
        "aws_query_dynamodb",
        aws_query_dynamodb,
        "Query a DynamoDB table",
        "inquisitive"
    )
    
    logging.info("Registered AWS tools with MCP server")

if __name__ == "__main__":
    # Test the AWS connector
    aws = AWSConnector()
    
    # Test uploading to S3
    if os.path.exists("test.txt"):
        s3_result = aws.upload_to_s3("test.txt")
        print(f"S3 upload result: {json.dumps(s3_result, indent=2)}")
    else:
        print("Create a test.txt file to test S3 upload")
    
    # Test invoking Lambda
    lambda_result = aws.invoke_lambda("test-function", {"message": "Hello from SoulCore!"})
    print(f"Lambda invocation result: {json.dumps(lambda_result, indent=2)}")
    
    # Test storing in DynamoDB
    dynamodb_store_result = aws.store_in_dynamodb("test-table", {"name": "Test Item", "value": 42})
    print(f"DynamoDB store result: {json.dumps(dynamodb_store_result, indent=2)}")
    
    # Test querying DynamoDB
    dynamodb_query_result = aws.query_dynamodb("test-table", "name", "Test Item")
    print(f"DynamoDB query result: {json.dumps(dynamodb_query_result, indent=2)}")
